# ==============================================================
# üß† VECTOR STORE MODULE ‚Äî StudyBuddy AI (LangChain v1.0+ & Ollama)
# ==============================================================

import os
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings  # ‚úÖ Updated import ‚Äî new official embedding class

# ‚úÖ Use a supported embedding model (works locally with Ollama)
EMBED_MODEL = "nomic-embed-text"

# Base directory for all vector databases
VECTOR_DB_DIR = os.path.join("vector_dbs")
os.makedirs(VECTOR_DB_DIR, exist_ok=True)


# -------------------------------------------------------------
# üß† Add a text file into the vector database for a specific subject
# -------------------------------------------------------------
def add_text_file_to_vector_db(text_file_path, subject_id):
    """Add extracted text into a Chroma vector store for a specific subject."""
    try:
        with open(text_file_path, "r", encoding="utf-8") as f:
            text_data = f.read()

        if not text_data.strip():
            print(f"‚ö†Ô∏è Empty text file: {text_file_path}")
            return 0

        # ‚úÖ Initialize embeddings with the new class
        embeddings = OllamaEmbeddings(model=EMBED_MODEL)

        # Folder for this subject‚Äôs vector store
        subject_db_dir = os.path.join(VECTOR_DB_DIR, f"subject_{subject_id}")
        os.makedirs(subject_db_dir, exist_ok=True)

        # Create Chroma vector store and persist
        db = Chroma.from_texts(
            [text_data],
            embedding=embeddings,
            persist_directory=subject_db_dir
        )
        db.persist()

        print(f"‚úÖ Added text to vector DB for subject {subject_id}")
        return 1

    except Exception as e:
        print(f"‚ùå Error adding to vector DB: {e}")
        return 0


# -------------------------------------------------------------
# üîç Retrieve the vector store for a given subject
# -------------------------------------------------------------
def get_vector_store(subject_id):
    """Load an existing Chroma vector store for the given subject."""
    try:
        subject_db_dir = os.path.join(VECTOR_DB_DIR, f"subject_{subject_id}")

        if not os.path.exists(subject_db_dir):
            raise FileNotFoundError(
                f"Vector DB for subject {subject_id} not found at {subject_db_dir}"
            )

        # ‚úÖ Use the updated embedding function
        embeddings = OllamaEmbeddings(model=EMBED_MODEL)

        # Load the stored Chroma DB
        db = Chroma(
            persist_directory=subject_db_dir,
            embedding_function=embeddings
        )
        print(f"‚úÖ Loaded vector store for subject {subject_id}")
        return db

    except Exception as e:
        print(f"‚ùå Error loading vector store: {e}")
        raise
